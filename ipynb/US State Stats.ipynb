{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "# Set up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# Insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../py')\n",
    "\n",
    "from choropleth_utils import ChoroplethUtilities\n",
    "from stats_scraping_utils import StatsScrapingUtilities\n",
    "from storage import Storage\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "s = Storage()\n",
    "ssu = StatsScrapingUtilities(s=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\StatsByCountry\\saves\\pkl\\all_countries_df.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_description_dict = s.load_object('column_description_dict')\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "\n",
    "all_countries_df = s.load_object('all_countries_df').set_index('country_code', drop=True)\n",
    "all_countries_df.country_name = all_countries_df.country_name.map(lambda x: ssu.country_name_dict.get(x, x))\n",
    "s.store_objects(all_countries_df=all_countries_df.reset_index(drop=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "---\n",
    "# Choropleths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['district_abbreviation', 'State_Region', 'Google_Suggest_Unique', 'label_line_d', 'Google_Suggest_Common', 'Google_Suggest_First', 'outline_d', 'Country_Equivalent_GDP', 'Country_Equivalent_Military_Expenditure', 'state_color', 'centroid_id']\n",
      "\n",
      "['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent', 'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score', 'Economy_Score', 'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score', 'Crime_Corrections_Score', 'Natural_Environment_Score', 'GDP_Rank', 'GDP_2018', 'GDP_Percent', 'Homicide_Rate_2018', 'Homicide_Rate_2017', 'Homicide_Rate_2014', 'Homicide_Rate_2010', 'Homicide_Rate_2005', 'Homicide_Rate_2000', 'Homicide_Rate_1996', 'Guns_Rank', 'Guns_Per_Capita', 'Guns_Registered', 'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016', 'Suicide_Deaths_2016', 'Suicide_Rate_2015', 'Suicide_Deaths_2015', 'Suicide_Rate_2014', 'Suicide_Deaths_2014', 'Suicide_Rate_2005', 'Suicide_Deaths_2005', 'Total_Inhabitants_2010', 'Inhabitants_Per_Square_Mile_2010', 'Total_Murder_Deaths_2010', 'Total_Gun_Murder_Deaths_2010', 'Gun_Ownership_Percent_2013', 'Murder_Rate_2010', 'Gun_Murder_Rate_2010', 'State_FIPS', 'State_Population', 'Gun_Suicide_Deaths', 'Gun_Suicide_Rate', 'text_x', 'text_y', 'Public_Access_to_Information', 'Political_Financing', 'Electoral_Oversight', 'Executive_Accountability', 'Legislative_Accountability', 'Judicial_Accountability', 'State_Budget_Processes', 'State_Civil_Service_Management', 'Procurement', 'Internal_Auditing', 'Lobbying_Disclosure', 'Ethics_Enforcement_Entities', 'State_Pension_Fund_Management', 'centroid_x', 'centroid_y', 'font_size', 'gdp_millions_usd_2021', 'gdp_millions_usd_2020', 'annual_change_usd', 'annual_change_percentage', 'real_gdp_growth_percentage', 'gdp_per_capita_2021', 'gdp_per_capita_2020', 'national_precentage_2021', 'national_precentage_2020', 'proportion_of_gdp_2021', 'gdp_proportion_of_military_expenditures_2021', 'dy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_descriptions_df = ssu.get_column_descriptions(c.one_country_df)\n",
    "mask_series = (column_descriptions_df.dtype == 'object')\n",
    "print(column_descriptions_df[mask_series].column_name.tolist())\n",
    "print()\n",
    "print(column_descriptions_df[~mask_series].column_name.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us_stats_df: ['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent', 'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score', 'Economy_Score', 'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score', 'Crime_Corrections_Score', 'Natural_Environment_Score', 'district_abbreviation', 'GDP_Rank', 'GDP_2018', 'GDP_Percent', 'State_Region', 'Homicide_Rate_2018', 'Homicide_Rate_2017', 'Homicide_Rate_2014', 'Homicide_Rate_2010', 'Homicide_Rate_2005', 'Homicide_Rate_2000', 'Homicide_Rate_1996', 'Guns_Rank', 'Guns_Per_Capita', 'Guns_Registered', 'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016', 'Suicide_Deaths_2016', 'Suicide_Rate_2015', 'Suicide_Deaths_2015', 'Suicide_Rate_2014', 'Suicide_Deaths_2014', 'Suicide_Rate_2005', 'Suicide_Deaths_2005', 'Total_Inhabitants_2010', 'Inhabitants_Per_Square_Mile_2010', 'Total_Murder_Deaths_2010', 'Total_Gun_Murder_Deaths_2010', 'Gun_Ownership_Percent_2013', 'Murder_Rate_2010', 'Gun_Murder_Rate_2010', 'State_FIPS', 'State_Population', 'Gun_Suicide_Deaths', 'Gun_Suicide_Rate', 'Google_Suggest_Unique', 'text_x', 'text_y', 'label_line_d', 'Google_Suggest_Common', 'Google_Suggest_First', 'Public_Access_to_Information', 'Political_Financing', 'Electoral_Oversight', 'Executive_Accountability', 'Legislative_Accountability', 'Judicial_Accountability', 'State_Budget_Processes', 'State_Civil_Service_Management', 'Procurement', 'Internal_Auditing', 'Lobbying_Disclosure', 'Ethics_Enforcement_Entities', 'State_Pension_Fund_Management', 'outline_d', 'centroid_x', 'centroid_y', 'Country_Equivalent_GDP', 'font_size', 'gdp_millions_usd_2021', 'gdp_millions_usd_2020', 'annual_change_usd', 'annual_change_percentage', 'real_gdp_growth_percentage', 'gdp_per_capita_2021', 'gdp_per_capita_2020', 'national_precentage_2021', 'national_precentage_2020', 'proportion_of_gdp_2021', 'gdp_proportion_of_military_expenditures_2021', 'Country_Equivalent_Military_Expenditure', 'state_color', 'centroid_id', 'dy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file_name in os.listdir(s.saves_pickle_folder):\n",
    "    if file_name.endswith('_df.pkl'):\n",
    "        df_name = file_name.split('.')[0]\n",
    "        df = s.load_object(df_name)\n",
    "        columns_list = df.columns.tolist()\n",
    "        if 'district_abbreviation' in columns_list:\n",
    "            print(f'{df_name}: {columns_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_editor_path = r'C:\\Program Files\\Notepad++\\notepad++.exe'\n",
    "inkscape_path = r'C:\\Program Files\\Inkscape\\bin\\inkscape.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = 'Estimated_IQ'\n",
    "if column_name in us_stats_df.columns:\n",
    "    svg_file_path = c.create_country_colored_map(column_name)\n",
    "    !\"{text_editor_path}\" \"{os.path.abspath(svg_file_path)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = 'White_Percent'\n",
    "if column_name in us_stats_df.columns:\n",
    "    svg_file_path = os.path.abspath(c.create_country_colored_map(column_name))\n",
    "    !\"{text_editor_path}\" \"{svg_file_path}\"\n",
    "    # !\"{inkscape_path}\" window-open \"{svg_file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = 'Percent_Whites_in_Non_Public_Education'\n",
    "if column_name in us_stats_df.columns:\n",
    "    svg_file_path = os.path.abspath(c.create_country_colored_map(column_name))\n",
    "    !\"{text_editor_path}\" \"{svg_file_path}\"\n",
    "    # !\"{inkscape_path}\" window-open \"{svg_file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'centroid_id' not in us_stats_df.columns:\n",
    "    us_stats_df['centroid_id'] = us_stats_df.index.map(lambda x: ('district-' + c.indexize_string(x)).replace('-district', ''))\n",
    "    s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'dy' not in us_stats_df.columns:\n",
    "    us_stats_df['dy'] = np.nan\n",
    "    s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "string_column_name = 'State_Region'\n",
    "if string_column_name in us_stats_df.columns:\n",
    "    c.create_label_line_file()\n",
    "    svg_file_path = os.path.abspath(c.create_country_labeled_map(string_column_name=string_column_name,\n",
    "                                                                 one_country_df=c.one_country_df))\n",
    "    !\"{text_editor_path}\" \"{svg_file_path}\"\n",
    "    !\"{inkscape_path}\" window-open \"{svg_file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_color_dict = s.load_object('us_state_name_color_dict')\n",
    "string_column_name = 'Google_Suggest_First'\n",
    "if string_column_name in us_stats_df.columns:\n",
    "    svg_file_path = os.path.abspath(c.create_country_labeled_map(string_column_name=string_column_name,\n",
    "                                                                 one_country_df=c.one_country_df))\n",
    "    !\"{text_editor_path}\" \"{svg_file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "ListedColormap_obj = cm.get_cmap('viridis', len(c.one_country_df.State_Budget_Processes.unique()))\n",
    "min = c.one_country_df.State_Budget_Processes.min()\n",
    "max = c.one_country_df.State_Budget_Processes.max()\n",
    "normed_series = (c.one_country_df.State_Budget_Processes - min) / (max - min)\n",
    "sample_value = normed_series.sample(1).tolist()[0]\n",
    "if str(sample_value) != 'nan':\n",
    "    print(ListedColormap_obj(sample_value), '#{:02x}{:02x}{:02x}{:02x}'.format(*tuple(int(x*255) for x in ListedColormap_obj(sample_value))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(['c.one_country_df.{}'.format(fn) for fn in dir(c.one_country_df) if 'sort' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!start %windir%\\explorer.exe \"{c.svg_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column_name in c.one_country_df.columns:\n",
    "    svg_file_path = c.create_country_colored_map(column_name=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(['c.one_country_df.{}'.format(cn) for cn in c.one_country_df.columns if ('gun' in cn.lower()) and ('murder' in cn.lower())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# O Canada!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(22, (140, 8)), (14, (122, 9)), (26, (78, 2)), (27, (37, 2)), (4, (28, 11)), (0, (26, 2)), (5, (25, 12)), (28, (25, 2)), (17, (24, 3)), (13, (22, 5)), (35, (21, 2)), (12, (18, 11)), (25, (18, 3)), (18, (17, 11)), (1, (14, 11)), (41, (13, 2)), (16, (11, 3)), (2, (10, 10)), (3, (10, 10)), (6, (8, 3)), (20, (8, 5)), (10, (7, 3)), (7, (6, 3)), (8, (6, 3)), (23, (6, 3)), (24, (6, 3)), (32, (6, 2)), (11, (5, 3)), (21, (5, 5)), (29, (5, 2)), (31, (5, 2)), (9, (4, 3)), (19, (4, 11)), (34, (4, 2)), (15, (3, 4)), (30, (3, 2)), (33, (3, 2)), (36, (2, 2)), (37, (2, 2)), (38, (2, 2)), (39, (2, 2)), (40, (2, 2)), (42, (2, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "page_tables_list = ssu.get_page_tables('https://en.wikipedia.org/wiki/Demographics_of_Canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "canada_races_df = page_tables_list[14].copy()\n",
    "canada_races_df.columns = [cn.split('[')[0].strip() for cn in canada_races_df.columns.droplevel(0).tolist()]\n",
    "canada_races_df['Province/territory'] = canada_races_df['Province/territory'].map(lambda cn: cn.split('[')[0])\n",
    "canada_races_df.set_index('Province/territory', drop=True, inplace=True)\n",
    "canada_races_df['Percent visible minority'] = canada_races_df['Percent visible minority'].map(lambda x: float(str(x).split('%')[0]))\n",
    "canada_races_df['Percent_White'] = canada_races_df['Percent visible minority'].map(lambda x: 100.0 - x)\n",
    "canada_races_df.dropna(axis='columns', how='all', inplace=True)\n",
    "canada_races_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(canada_races_df=canada_races_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Add New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.columns = ['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent',\n",
    "                       'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score',\n",
    "                       'Economy_Score', 'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score',\n",
    "                       'Crime_Corrections_Score', 'Natural_Environment_Score', 'district_abbreviation', 'GDP_Rank', 'GDP_2018',\n",
    "                       'GDP_Percent', 'State_Region', 'Homicide_Rate_2018', 'Homicide_Rate_2017', 'Homicide_Rate_2014',\n",
    "                       'Homicide_Rate_2010', 'Homicide_Rate_2005', 'Homicide_Rate_2000', 'Homicide_Rate_1996', 'Guns_Rank',\n",
    "                       'Guns_Per_Capita', 'Guns_Registered', 'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016',\n",
    "                       'Suicide_Deaths_2016', 'Suicide_Rate_2015', 'Suicide_Deaths_2015', 'Suicide_Rate_2014',\n",
    "                       'Suicide_Deaths_2014', 'Suicide_Rate_2005', 'Suicide_Deaths_2005',\n",
    "                       'Total_Inhabitants_2010', 'Inhabitants_Per_Square_Mile_2010', 'Total_Murder_Deaths_2010',\n",
    "                       'Total_Gun_Murder_Deaths_2010', 'Gun_Ownership_Percent_2013', 'Murder_Rate_2010', 'Gun_Murder_Rate_2010',\n",
    "                       'State_FIPS', 'State_Population', 'Gun_Suicide_Deaths', 'Gun_Suicide_Rate', 'Google_Suggest_Unique', 'text_x',\n",
    "                       'text_y', 'label_line_d', 'Google_Suggest_Common', 'Google_Suggest_First',\n",
    "                       'Public_Access_to_Information', 'Political_Financing', 'Electoral_Oversight',\n",
    "                       'Executive_Accountability', 'Legislative_Accountability', 'Judicial_Accountability',\n",
    "                       'State_Budget_Processes', 'State_Civil_Service_Management', 'Procurement', 'Internal_Auditing',\n",
    "                       'Lobbying_Disclosure', 'Ethics_Enforcement_Entities', 'State_Pension_Fund_Management', 'outline_d',\n",
    "                       'centroid_x', 'centroid_y']\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "file_path = os.path.join(s.data_folder, 'svg', 'us.svg')\n",
    "#print(['root.{}'.format(fn) for fn in dir(root) if not fn.startswith('_')])\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "root = et.parse(file_path).getroot()\n",
    "outline_d_dict = {}\n",
    "for tag in root:\n",
    "    if (tag.tag.split('}')[-1] == 'path'):\n",
    "        #print(['tag.{}'.format(fn) for fn in dir(tag) if not fn.startswith('_')])\n",
    "        state_name = tag.attrib['data-name']\n",
    "        outline_d = tag.attrib['d']\n",
    "        outline_d_dict[state_name] = outline_d\n",
    "\n",
    "df = pd.DataFrame([outline_d_dict]).T\n",
    "df.columns = ['outline_d']\n",
    "us_stats_df = us_stats_df.T.append(df.T).T\n",
    "us_stats_df.T.tail(5).T.sample(7).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = 'State_Integrity_2015_Full_Dataset.xlsx'\n",
    "excel_path = os.path.join(s.data_folder, 'xlsx', file_name)\n",
    "sheet_df_dict = pd.read_excel(excel_path, sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "for sheet_name in sheet_df_dict.keys():\n",
    "    column_name = '_'.join(sheet_name.strip().split(' '))\n",
    "    df = sheet_df_dict[sheet_name].copy()\n",
    "    index_columns = df.loc[0, ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2']].tolist()\n",
    "    df.columns = index_columns + df.columns.tolist()[3:]\n",
    "    df.set_index(keys=index_columns, inplace=True)\n",
    "    cn_dict = {}\n",
    "    for state_name in us_stats_df.index:\n",
    "        cn_dict[state_name] = []\n",
    "    for index_tuple, row_series in df[states_list].iterrows():\n",
    "        if str(index_tuple[1]).isdigit():\n",
    "            #print(index_tuple)\n",
    "            for state_name, column_value in row_series.iteritems():\n",
    "                state_name = state_name.strip()\n",
    "                column_value = column_value.strip()\n",
    "                if str(column_value).isdigit():\n",
    "                    scores_list = cn_dict[state_name]\n",
    "                    scores_list.append(column_value)\n",
    "                    cn_dict[state_name] = scores_list\n",
    "                elif column_value.lower() in ['no', 'moderate', 'yes']:\n",
    "                    scores_list = cn_dict[state_name]\n",
    "                    scores_list.append(['no', 'moderate', 'yes'].index(column_value.lower())*50)\n",
    "                    cn_dict[state_name] = scores_list\n",
    "    cn_dict = {state_name: sum([b/len(scores_list) for b in scores_list]) for state_name,\n",
    "               scores_list in cn_dict.items()}\n",
    "    df = pd.DataFrame([cn_dict]).T\n",
    "    df.columns = [column_name]\n",
    "    us_stats_df = us_stats_df.T.append(df.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.T.tail(20).T.sample(8).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Get Correlations (\"P-Hunting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_correlation_dataframe(numeric_columns_list):\n",
    "    rows_list = []\n",
    "    for x_column in numeric_columns_list:\n",
    "        for y_column in numeric_columns_list:\n",
    "            if x_column != y_column:\n",
    "                columns_list = [x_column, y_column]\n",
    "                df = us_stats_df[columns_list].dropna()\n",
    "                x = df[x_column].values\n",
    "                y = df[y_column].values\n",
    "                try:\n",
    "                    r_tuple = stats.pearsonr(x, y)\n",
    "                    if r_tuple[1] < 0.05:\n",
    "                        row_dict = {}\n",
    "                        row_dict['left_column'] = x_column\n",
    "                        row_dict['right_column'] = y_column\n",
    "                        row_dict['pearson_r'] = abs(r_tuple[0])\n",
    "                        rows_list.append(row_dict)\n",
    "                except Exception as e:\n",
    "                    print('{} and {} get an error: {}'.format(x_column, y_column, e))\n",
    "    correlation_df = pd.DataFrame(rows_list, columns=['left_column', 'right_column', 'pearson_r'])\n",
    "    \n",
    "    return correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_descriptions_df = ssu.get_column_descriptions(df=us_stats_df)\n",
    "column_descriptions_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (column_descriptions_df.dtype == 'float32')\n",
    "columns_list = [row_series.column_name for row_index, row_series in column_descriptions_df[mask_series].iterrows()]\n",
    "correlation_df = get_correlation_dataframe(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (correlation_df.pearson_r > 0.95)\n",
    "correlation_df[mask_series].sort_values('pearson_r', ascending=False).left_column.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_correlation_dataframe(x_column_list, y_column_list):\n",
    "    rows_list = []\n",
    "    for x_column in x_column_list:\n",
    "        for y_column in y_column_list:\n",
    "            if x_column != y_column:\n",
    "                columns_list = [x_column, y_column]\n",
    "                df = us_stats_df[columns_list].dropna()\n",
    "                x = df[x_column].values\n",
    "                y = df[y_column].values\n",
    "                try:\n",
    "                    r_tuple = stats.pearsonr(x, y)\n",
    "                    if r_tuple[1] < 0.05:\n",
    "                        row_dict = {}\n",
    "                        row_dict['left_column'] = x_column\n",
    "                        row_dict['right_column'] = y_column\n",
    "                        row_dict['pearson_r'] = abs(r_tuple[0])\n",
    "                        rows_list.append(row_dict)\n",
    "                except Exception as e:\n",
    "                    print('{} and {} get an error: {}'.format(x_column, y_column, e))\n",
    "    correlation_df = pd.DataFrame(rows_list, columns=['left_column', 'right_column', 'pearson_r'])\n",
    "    \n",
    "    return correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (column_descriptions_df.dtype == 'float32')\n",
    "numeric_columns_list = [row_series.column_name for row_index, row_series in column_descriptions_df[mask_series].iterrows()]\n",
    "new_columns_list = us_stats_df.T.tail(13).index.tolist()\n",
    "old_columns_list = list(set(numeric_columns_list) - set(new_columns_list))\n",
    "correlation_df = get_correlation_dataframe(new_columns_list, old_columns_list)\n",
    "correlation_df.sort_values('pearson_r', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Linear Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_linear_scatterplot(merged_df, columns_list, ev_min_str=None, ev_max_str=None, rv_min_str=None, rv_max_str=None):\n",
    "    ev_column_name = columns_list[0]\n",
    "    rv_column_name = columns_list[1]\n",
    "    explanatory_variable = get_column_description(ev_column_name)\n",
    "    response_variable = get_column_description(rv_column_name)\n",
    "    if (ev_min_str is None):\n",
    "        ev_min_str = 'minimum {}'.format(explanatory_variable)\n",
    "    if (ev_max_str is None):\n",
    "        ev_max_str = 'maximum {}'.format(explanatory_variable)\n",
    "    if (rv_min_str is None):\n",
    "        rv_min_str = 'minimum {}'.format(response_variable)\n",
    "    if (rv_max_str is None):\n",
    "        rv_max_str = 'maximum {}'.format(response_variable)\n",
    "    \n",
    "    df = merged_df.copy()\n",
    "    columns_list = [ev_column_name, rv_column_name]\n",
    "    df = df[columns_list].dropna()\n",
    "    ev_max = df[ev_column_name].max()\n",
    "    ev_min = df[ev_column_name].min()\n",
    "    rv_min = df[rv_column_name].min()\n",
    "    rv_max = df[rv_column_name].max()\n",
    "    ev_max_labeled = False\n",
    "    ev_min_labeled = False\n",
    "    rv_min_labeled = False\n",
    "    rv_max_labeled = False\n",
    "    \n",
    "    # First order (linear) scatterplot\n",
    "    fig1_fig = plt.figure(figsize=(12, 8))\n",
    "    merge_axes_subplot = sns.regplot(x=ev_column_name, y=rv_column_name,\n",
    "                                     scatter=True, data=df)\n",
    "    xlabel_text = plt.xlabel('{} (explanatory variable)'.format(explanatory_variable))\n",
    "    ylabel_text = plt.ylabel('{} (response variable)'.format(response_variable))\n",
    "    \n",
    "    # Add annotations\n",
    "    for label, x, y in zip(df.index, df[ev_column_name], df[rv_column_name]):\n",
    "        if (x == ev_min):\n",
    "            if not ev_min_labeled:\n",
    "                ev_min_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, ev_min_str), xy=(x, y), xytext=ev_min_xytext, **kwargs)\n",
    "        elif (x == ev_max):\n",
    "            if not ev_max_labeled:\n",
    "                ev_max_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, ev_max_str), xy=(x, y), xytext=ev_max_xytext, **kwargs)\n",
    "        elif (y == rv_min):\n",
    "            if not rv_min_labeled:\n",
    "                rv_min_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, rv_min_str), xy=(x, y), xytext=rv_min_xytext, **kwargs)\n",
    "        elif (y == rv_max):\n",
    "            if not rv_max_labeled:\n",
    "                rv_max_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, rv_max_str), xy=(x, y), xytext=rv_max_xytext, **kwargs)\n",
    "        elif (label == 'Arizona'):\n",
    "            annotation = plt.annotate('{} (my home state)'.format(label), xy=(x, y), xytext=az_xytext, **kwargs)\n",
    "    \n",
    "    # Add r-squared\n",
    "    x = df[ev_column_name].values\n",
    "    y = df[rv_column_name].values\n",
    "    plt.text(0.92, 0.965, r'$r^2 = {0:.2}$'.format(stats.pearsonr(x, y)[0] ** 2), fontsize=20, alpha=0.25,\n",
    "             horizontalalignment='center', verticalalignment='center', transform=merge_axes_subplot.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_column_description(column_name):\n",
    "    if column_name in column_description_dict:\n",
    "        column_description = column_description_dict[column_name]\n",
    "    else:\n",
    "        column_description = re.sub('^pf_', 'Personal Freedom:_', str(column_name), 1)\n",
    "        column_description = re.sub('^hf_', 'Human Freedom:_', str(column_description), 1)\n",
    "        column_description = re.sub('^ef_', 'Economic Freedom:_', str(column_description), 1)\n",
    "        column_list = column_description.split('_')\n",
    "        descr_list = []\n",
    "        for word in column_list:\n",
    "            descr_list.append(word[0].upper()+word[1:])\n",
    "        column_description = ' '.join(descr_list)\n",
    "        column_description_dict[column_name] = column_description\n",
    "        s.store_objects(column_description_dict=column_description_dict)\n",
    "    \n",
    "    return column_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'State_Budget_Processes'\n",
    "\n",
    "rv_column_name = 'Homicide_Rate_2018'\n",
    "\n",
    "ev_min_str = 'worst process'\n",
    "ev_max_str = 'best process'\n",
    "rv_min_str = 'least murderous'\n",
    "rv_max_str = 'most murderous'\n",
    "ev_min_xytext = (-5, -40)\n",
    "ev_max_xytext = (-100, -40)\n",
    "rv_min_xytext = (-45, -35)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (0, 30)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlation_df = get_correlation_dataframe(new_columns_list, new_columns_list)\n",
    "correlation_df.sort_values('pearson_r', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'Executive_Accountability'\n",
    "\n",
    "rv_column_name = 'Legislative_Accountability'\n",
    "\n",
    "ev_min_str = 'least executive accountability'\n",
    "ev_max_str = 'most executive accountability'\n",
    "rv_min_str = 'least legislative accountability'\n",
    "rv_max_str = 'most legislative accountability'\n",
    "ev_min_xytext = (15, 5)\n",
    "ev_max_xytext = (-210, -30)\n",
    "rv_min_xytext = (-45, -35)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (-15, 10)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'Guns_Registered'\n",
    "rv_column_name = 'Suicide_Deaths_2017'\n",
    "\n",
    "ev_min_str = 'least gun-nutty'\n",
    "ev_max_str = 'most gun-nutty'\n",
    "rv_min_str = 'least suicidal'\n",
    "rv_max_str = 'most suicidal'\n",
    "ev_min_xytext = (50, -10)\n",
    "ev_max_xytext = (-150, -60)\n",
    "rv_min_xytext = (20, -15)\n",
    "rv_max_xytext = (100, -50)\n",
    "az_xytext = (60, 50)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "df = us_stats_df[columns_list+['Total_Inhabitants_2010']].copy()\n",
    "df[ev_column_name] = df[ev_column_name]/df['Total_Inhabitants_2010']\n",
    "df[rv_column_name] = df[rv_column_name]/df['Total_Inhabitants_2010']\n",
    "mask_series = (df.index == 'Wyoming')\n",
    "show_linear_scatterplot(df[~mask_series], columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, (52, 8)), (0, (50, 4))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "tables_url = 'https://en.wikipedia.org/wiki/Firearm_death_rates_in_the_United_States_by_state'\n",
    "tables_df_list = ssu.get_page_tables(tables_url, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.district_abbreviation.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gun_murders_df = tables_df_list[4].copy()\n",
    "gun_murders_df.set_index('State', inplace=True)\n",
    "print(gun_murders_df.columns.tolist())\n",
    "gun_murders_df.columns = ['Total_Inhabitants_2010', 'Inhabitants_Per_Square_Mile_2010', 'Total_Murder_Deaths_2010',\n",
    "                          'Total_Gun_Murder_Deaths_2010', 'Gun_Ownership_Percent_2013', 'Murder_Rate_2010',\n",
    "                          'Gun_Murder_Rate_2010']\n",
    "gun_murders_df.Gun_Ownership_Percent_2013 = gun_murders_df.Gun_Ownership_Percent_2013.map(lambda x: float(str(x).split('%')[0]))\n",
    "gun_murders_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gun_suicides_df = s.load_csv(csv_name='gun_suicides_by_state',\n",
    "                             folder_path=s.data_folder).dropna(axis=0, how='all').dropna(axis='columns', how='all')\n",
    "gun_suicides_df = gun_suicides_df.iloc[11:].dropna(axis='columns', how='all')\n",
    "abbrev_dict = {row_series.district_abbreviation: state_name for state_name, row_series in us_stats_df.iterrows()}\n",
    "abbrev_dict['DC'] = 'District of Columbia'\n",
    "gun_suicides_df.ST = gun_suicides_df.ST.map(lambda x: abbrev_dict[x])\n",
    "gun_suicides_df.columns = ['State', 'State_FIPS', 'State_Population', 'Gun_Suicide_Deaths', 'Gun_Suicide_Rate']\n",
    "gun_suicides_df.set_index('State', inplace=True)\n",
    "gun_suicides_df.Gun_Suicide_Rate = gun_suicides_df.Gun_Suicide_Rate.map(lambda x: float(x))\n",
    "for column_name in ['State_FIPS', 'State_Population', 'Gun_Suicide_Deaths']:\n",
    "    gun_suicides_df[column_name] = gun_suicides_df[column_name].map(lambda x: int(x))\n",
    "gun_suicides_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "set(gun_merge_df.columns).intersection(set(us_stats_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent',\n",
    "                'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score', 'Economy_Score',\n",
    "                'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score', 'Crime_Corrections_Score',\n",
    "                'Natural_Environment_Score', 'district_abbreviation', 'GDP_Rank', 'GDP_2018', 'GDP_Percent', 'State_Region',\n",
    "                'Homicide_Rate_2018', 'Homicide_Rate_2017', 'Homicide_Rate_2014', 'Homicide_Rate_2010', 'Homicide_Rate_2005',\n",
    "                'Homicide_Rate_2000', 'Homicide_Rate_1996', 'Guns_Rank', 'Guns_Per_Capita', 'Guns_Registered',\n",
    "                'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016', 'Suicide_Deaths_2016', 'Suicide_Rate_2015',\n",
    "                'Suicide_Deaths_2015', 'Suicide_Rate_2014', 'Suicide_Deaths_2014', 'Suicide_Rate_2005', 'Suicide_Deaths_2005']\n",
    "us_stats_df = pd.merge(left=us_stats_df[columns_list], right=gun_merge_df, left_index=True,\n",
    "                          right_index=True, suffixes=('_merge', '_guns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_descriptions_df = ssu.get_column_descriptions(df=us_stats_df, column_list=us_stats_df.columns)\n",
    "mask_series = (column_descriptions_df.dtype.isin(['int64', 'float64']))\n",
    "print(column_descriptions_df[~mask_series].column_name.tolist())\n",
    "column_descriptions_df[~mask_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_descriptions_df = ssu.get_column_descriptions(us_stats_df)\n",
    "column_descriptions_df['dtype'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_series = (column_descriptions_df['dtype'].isin(['int64', 'float64']))\n",
    "numeric_columns_list = column_descriptions_df[mask_series]['column_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column_name in numeric_columns_list:\n",
    "    us_stats_df[column_name] = pd.to_numeric(us_stats_df[column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "r_columns_list = []\n",
    "rows_list = []\n",
    "for x_column in numeric_columns_list:\n",
    "    for y_column in numeric_columns_list:\n",
    "        if x_column != y_column:\n",
    "            columns_list = [x_column, y_column]\n",
    "            df = us_stats_df[columns_list].dropna()\n",
    "            x = df[x_column].values\n",
    "            y = df[y_column].values\n",
    "            try:\n",
    "                r_tuple = stats.pearsonr(x, y)\n",
    "                if r_tuple[1] < 0.05:\n",
    "                    c_tuple = ('/'.join(columns_list), row_dict['pearson_r'])\n",
    "                    r_columns_list.append(c_tuple)\n",
    "            except Exception as e:\n",
    "                print('{} and {} get an error: {}'.format(x_column, y_column, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_pairs_list = sorted(r_columns_list, key=lambda x: x[1], reverse=True)\n",
    "[column_pairs_list[0][0].split('/')[0], column_pairs_list[0][0].split('/')[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'Guns_Registered'\n",
    "column_description_dict[ev_column_name] = 'Number of Guns Registered'\n",
    "#s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "rv_column_name = 'Gun_Murder_Rate_2010'\n",
    "column_description_dict[rv_column_name] = 'Gun Murder Rate'\n",
    "s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "ev_min_str = 'least gun-nutty'\n",
    "ev_max_str = 'most gun-nutty'\n",
    "rv_min_str = 'least murderous'\n",
    "rv_max_str = 'most murderous'\n",
    "ev_min_xytext = (-5, 90)\n",
    "ev_max_xytext = (-130, -60)\n",
    "rv_min_xytext = (20, -15)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (-60, 50)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from scipy import stats\n",
    "%run ../load_magic/dataframes.py\n",
    "\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'Guns_Registered'\n",
    "column_description_dict[ev_column_name] = 'Number of Guns Registered'\n",
    "#s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "rv_column_name = 'Gun_Suicide_Deaths'\n",
    "column_description_dict[rv_column_name] = 'Gun Suicide Deaths'\n",
    "s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "ev_min_str = 'least gun-nutty'\n",
    "ev_max_str = 'most gun-nutty'\n",
    "rv_min_str = 'least suicidal'\n",
    "rv_max_str = 'most suicidal'\n",
    "ev_min_xytext = (-5, 110)\n",
    "ev_max_xytext = (-130, -60)\n",
    "rv_min_xytext = (20, -30)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (-60, 50)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows_list = []\n",
    "for row_index, row_series in correlation_df.sort_values('pearson_r', ascending=False).iterrows():\n",
    "    left_column = row_series['left_column']\n",
    "    right_column = row_series['right_column']\n",
    "    if ('gun' in left_column.lower()) or ('gun' in right_column.lower()):\n",
    "        rows_list.append(row_series.to_dict())\n",
    "pd.DataFrame(rows_list).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows_list = []\n",
    "for row_index, row_series in correlation_df.sort_values('pearson_r', ascending=False).iterrows():\n",
    "    left_column = row_series['left_column']\n",
    "    right_column = row_series['right_column']\n",
    "    if ('gun' in left_column.lower()) or ('gun' in right_column.lower()):\n",
    "        rows_list.append(row_series.to_dict())\n",
    "pd.DataFrame(rows_list).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(['row_series.{}'.format(fn) for fn in dir(row_series) if 'dict' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (52, 3))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tables_url = 'https://www.thoughtco.com/gun-owners-percentage-of-state-populations-3325153'\n",
    "tables_df_list = ssu.get_page_tables(tables_url, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nutty_df = tables_df_list[0].dropna(axis=0, how='all').dropna(axis='columns', how='all')\n",
    "nutty_df.columns = ['Guns_Rank', 'State', 'Guns_Per_Capita', 'Guns_Registered']\n",
    "nutty_df = nutty_df.iloc[1:]\n",
    "nutty_df.set_index('State', inplace=True)\n",
    "us_stats_df = pd.merge(left=us_stats_df, right=nutty_df, left_index=True,\n",
    "                          right_index=True, suffixes=('_merge', '_nutty'))\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "suicide_df = s.load_csv(csv_name='Suicide Mortality by State',\n",
    "                        folder_path=s.data_folder).dropna(axis=0, how='all').dropna(axis='columns', how='all')\n",
    "columns_list = ['Suicide_Year', 'district_abbreviation', 'Suicide_Rate', 'Suicide_Deaths']\n",
    "suicide_df.columns = columns_list + ['URL']\n",
    "suicide_df = suicide_df[columns_list]\n",
    "suicide_df.Suicide_Year = suicide_df.Suicide_Year.map(lambda x: int(x))\n",
    "suicide_df = s.load_csv(csv_name='Suicide Mortality by State',\n",
    "                        folder_path=s.data_folder).dropna(axis=0, how='all').dropna(axis='columns', how='all')\n",
    "suicide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for year in suicide_df.Suicide_Year.unique():\n",
    "    mask_series = (suicide_df.Suicide_Year == year)\n",
    "    df = suicide_df[mask_series]\n",
    "    columns_list = ['district_abbreviation', 'Suicide_Rate_{}'.format(year),\n",
    "                    'Suicide_Deaths_{}'.format(year)]\n",
    "    df.columns = ['Suicide_Year'] + columns_list\n",
    "    df = df[columns_list]\n",
    "    us_stats_df = pd.merge(left=us_stats_df, right=df, how='inner', on='district_abbreviation', suffixes=('_merge', '_suicide'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(us_stats_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "for column_name in ['Guns_Rank', 'Guns_Registered']:\n",
    "    us_stats_df[column_name] = us_stats_df[column_name].map(lambda x: int(x))\n",
    "us_stats_df.Guns_Per_Capita = us_stats_df.Guns_Per_Capita.map(lambda x: float(x))\n",
    "for year in [2005, 2014, 2015, 2016, 2017]:\n",
    "    for infix in ['Rate', 'Deaths']:\n",
    "        column_name = 'Suicide_{}_{}'.format(infix, year)\n",
    "        us_stats_df[column_name] = us_stats_df[column_name].map(lambda x: int(re.sub(r'[^0-9\\.]+', '', str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.Suicide_Deaths_2017.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, (60, 2))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#us_stats_df['district_abbreviation']\n",
    "file_path = os.path.join(s.data_folder, 'html', 'us_state_abbreviations.html')\n",
    "#tables_url = 'https://www.50states.com/abbreviations.htm'\n",
    "tables_df_list = ssu.get_page_tables(file_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abbrevs_df = tables_df_list[0].dropna(axis=0, how='all').dropna(axis='columns', how='all')\n",
    "abbrevs_df.columns = ['State', 'district_abbreviation']\n",
    "us_stats_df = pd.merge(left=us_stats_df, right=abbrevs_df, on='district_abbreviation', suffixes=('_merge', '_abbrevs'))\n",
    "us_stats_df.set_index('State', inplace=True)\n",
    "us_stats_df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_list = ['Guns_Rank', 'Guns_Per_Capita', 'Guns_Registered', 'Suicide_Rate_2017', 'Suicide_Deaths_2017', 'Suicide_Rate_2016',\n",
    "                'Suicide_Deaths_2016', 'Suicide_Rate_2015', 'Suicide_Deaths_2015', 'Suicide_Rate_2014', 'Suicide_Deaths_2014',\n",
    "                'Suicide_Rate_2005', 'Suicide_Deaths_2005']\n",
    "ssu.get_column_descriptions(df=us_stats_df, column_list=columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_max_rsquared_adj(df=us_stats_df, columns_list=columns_list,\n",
    "                     verbose=False).sort_values('max_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the following only if you are on a high definition device\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "basecolor_list = list(mcolors.BASE_COLORS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from scipy import stats\n",
    "%run ../load_magic/dataframes.py\n",
    "\n",
    "us_stats_df = s.load_object('us_stats_df')\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ev_column_name = 'Guns_Registered'\n",
    "column_description_dict[ev_column_name] = 'Number of Guns Registered'\n",
    "s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "rv_column_name = 'Suicide_Deaths_2017'\n",
    "column_description_dict[rv_column_name] = 'Suicide Deaths in 2017'\n",
    "s.store_objects(column_description_dict=column_description_dict)\n",
    "\n",
    "ev_min_str = 'least gun-nutty'\n",
    "ev_max_str = 'most gun-nutty'\n",
    "rv_min_str = 'least suicidal'\n",
    "rv_max_str = 'most suicidal'\n",
    "ev_min_xytext = (-5, 150)\n",
    "ev_max_xytext = (-130, -100)\n",
    "rv_min_xytext = (20, -30)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (-80, 50)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str,\n",
    "                        ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tables_url = 'https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_GDP'\n",
    "tables_df_list = pd.read_html(tables_url)\n",
    "print([(i, df.shape) for (i, df) in enumerate(tables_df_list) if df.shape[0] > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_gdps_df = tables_df_list[2].dropna(axis=0, how='all').dropna(axis='columns', how='all')\n",
    "state_gdps_df.columns = ['Rank', 'State', '2018', '% of Nation', 'Region']\n",
    "state_gdps_df = state_gdps_df.iloc[1:]\n",
    "state_gdps_df.set_index('State', inplace=True)\n",
    "for column_name in ['Rank', '2018']:\n",
    "    state_gdps_df[column_name] = state_gdps_df[column_name].map(lambda x: int(str(x).split('[')[0]))\n",
    "for column_name in ['% of Nation']:\n",
    "    state_gdps_df[column_name] = state_gdps_df[column_name].map(lambda x: float(str(x).split('[')[0]))\n",
    "for column_name in ['Region']:\n",
    "    state_gdps_df[column_name] = state_gdps_df[column_name].map(lambda x: str(x).split('[')[0])\n",
    "state_gdps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df = load_object('us_stats_df')\n",
    "print(us_stats_df.shape, state_gdps_df.shape)\n",
    "us_stats_df = pd.merge(left=us_stats_df, right=state_gdps_df, left_index=True, right_index=True, suffixes=('_merge', '_gdp'))\n",
    "print(us_stats_df.shape)\n",
    "us_stats_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.columns = ['White_Percent', 'Black_Percent', 'Hispanic_Percent', 'Asian_Percent', 'Native_Percent', 'Islander_Percent',\n",
    "                          'Multi_Percent', 'Gini_Index', 'Effectiveness_Rank', 'Health_Care_Score', 'Education_Score', 'Economy_Score',\n",
    "                          'Infrastructure_Score', 'Opportunity_Score', 'Fiscal_Stability_Score', 'Crime_Corrections_Score',\n",
    "                          'Natural_Environment_Score', 'district_abbreviation', 'GDP_Rank', 'GDP_2018', 'GDP_Percent', 'State_Region']\n",
    "store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.sample(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the following only if you are on a high definition device\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "explanatory_variable = 'Effectiveness Rank'\n",
    "ev_column_name = 'Effectiveness_Rank'\n",
    "response_variable = 'GDP Rank'\n",
    "rv_column_name = 'GDP_Rank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = us_stats_df.copy()\n",
    "ev_min_str = 'most effective'\n",
    "ev_max_str = 'least effective'\n",
    "rv_min_str = 'highest GDP'\n",
    "rv_max_str = 'lowest GDP'\n",
    "ev_min_xytext = (-5, 150)\n",
    "ev_max_xytext = (-135, -30)\n",
    "rv_min_xytext = (20, -10)\n",
    "rv_max_xytext = (-100, -50)\n",
    "us_xytext = (-90, 40)\n",
    "\n",
    "fig1_fig = plt.figure(figsize=(12,8))\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "df = df[columns_list].dropna()\n",
    "\n",
    "# First order (linear) scatterplot\n",
    "merge_axes_subplot = sns.regplot(x=ev_column_name, y=rv_column_name,\n",
    "                                 scatter=True, data=df)\n",
    "xlabel_text = plt.xlabel('{} (explanatory variable)'.format(explanatory_variable))\n",
    "ylabel_text = plt.ylabel('{} (response variable)'.format(response_variable))\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "ev_max = df[ev_column_name].max()\n",
    "ev_min = df[ev_column_name].min()\n",
    "rv_min = df[rv_column_name].min()\n",
    "rv_max = df[rv_column_name].max()\n",
    "for label, x, y in zip(df.index, df[ev_column_name], df[rv_column_name]):\n",
    "    if (x == ev_min):\n",
    "        annotation = plt.annotate('{} ({})'.format(label, ev_min_str), xy=(x, y), xytext=ev_min_xytext, **kwargs)\n",
    "    elif (x == ev_max):\n",
    "        annotation = plt.annotate('{} ({})'.format(label, ev_max_str), xy=(x, y), xytext=ev_max_xytext, **kwargs)\n",
    "    elif (y == rv_min):\n",
    "        annotation = plt.annotate('{} ({})'.format(label, rv_min_str), xy=(x, y), xytext=rv_min_xytext, **kwargs)\n",
    "    elif (y == rv_max):\n",
    "        annotation = plt.annotate('{} ({})'.format(label, rv_max_str), xy=(x, y), xytext=rv_max_xytext, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tables_url = 'https://en.wikipedia.org/wiki/List_of_U.S._states_by_homicide_rate'\n",
    "tables_df_list = pd.read_html(tables_url)\n",
    "print([(i, df.shape) for (i, df) in enumerate(tables_df_list) if df.shape[0] >= 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "homicide_df = tables_df_list[0]\n",
    "homicide_df.set_index('State', inplace=True)\n",
    "for column_name in homicide_df.columns:\n",
    "    homicide_df[column_name] = homicide_df[column_name].map(lambda x: float(x))\n",
    "homicide_df.columns = ['Homicide_Rate_{}'.format(cn) for cn in homicide_df.columns]\n",
    "homicide_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(us_stats_df.shape, homicide_df.shape)\n",
    "us_stats_df = pd.merge(left=us_stats_df, right=homicide_df, left_index=True, right_index=True, suffixes=('_merge', '_homicide'))\n",
    "print(us_stats_df.shape)\n",
    "us_stats_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "us_stats_df.sample(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the following only if you are on a high definition device\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "explanatory_variable = 'Percent Black'\n",
    "ev_column_name = 'Black_Percent'\n",
    "response_variable = 'Homicide Rate 2014'\n",
    "rv_column_name = 'Homicide_Rate_2014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_linear_scatterplot(merged_df, columns_list, ev_min_str=None, ev_max_str=None, rv_min_str=None, rv_max_str=None):\n",
    "    ev_column_name = columns_list[0]\n",
    "    rv_column_name = columns_list[1]\n",
    "    explanatory_variable = get_column_description(ev_column_name)\n",
    "    response_variable = get_column_description(rv_column_name)\n",
    "    if (ev_min_str is None):\n",
    "        ev_min_str = 'minimum {}'.format(explanatory_variable)\n",
    "    if (ev_max_str is None):\n",
    "        ev_max_str = 'maximum {}'.format(explanatory_variable)\n",
    "    if (rv_min_str is None):\n",
    "        rv_min_str = 'minimum {}'.format(response_variable)\n",
    "    if (rv_max_str is None):\n",
    "        rv_max_str = 'maximum {}'.format(response_variable)\n",
    "    \n",
    "    df = merged_df.copy()\n",
    "    columns_list = [ev_column_name, rv_column_name]\n",
    "    df = df[columns_list].dropna()\n",
    "    ev_max = df[ev_column_name].max()\n",
    "    ev_min = df[ev_column_name].min()\n",
    "    rv_min = df[rv_column_name].min()\n",
    "    rv_max = df[rv_column_name].max()\n",
    "    ev_max_labeled = False\n",
    "    ev_min_labeled = False\n",
    "    rv_min_labeled = False\n",
    "    rv_max_labeled = False\n",
    "    \n",
    "    # First order (linear) scatterplot\n",
    "    fig1_fig = plt.figure(figsize=(12,8))\n",
    "    merge_axes_subplot = sns.regplot(x=ev_column_name, y=rv_column_name,\n",
    "                                     scatter=True, data=df)\n",
    "    xlabel_text = plt.xlabel('{} (explanatory variable)'.format(explanatory_variable))\n",
    "    ylabel_text = plt.ylabel('{} (response variable)'.format(response_variable))\n",
    "    \n",
    "    # Add annotations\n",
    "    for label, x, y in zip(df.index, df[ev_column_name], df[rv_column_name]):\n",
    "        if (x == ev_min):\n",
    "            if not ev_min_labeled:\n",
    "                ev_min_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, ev_min_str), xy=(x, y), xytext=ev_min_xytext, **kwargs)\n",
    "        elif (x == ev_max):\n",
    "            if not ev_max_labeled:\n",
    "                ev_max_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, ev_max_str), xy=(x, y), xytext=ev_max_xytext, **kwargs)\n",
    "        elif (y == rv_min):\n",
    "            if not rv_min_labeled:\n",
    "                rv_min_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, rv_min_str), xy=(x, y), xytext=rv_min_xytext, **kwargs)\n",
    "        elif (y == rv_max):\n",
    "            if not rv_max_labeled:\n",
    "                rv_max_labeled = True\n",
    "                annotation = plt.annotate('{} ({})'.format(label, rv_max_str), xy=(x, y), xytext=rv_max_xytext, **kwargs)\n",
    "        elif (label == 'Arizona'):\n",
    "            annotation = plt.annotate('{} (my home state)'.format(label), xy=(x, y), xytext=az_xytext, **kwargs)\n",
    "    \n",
    "    # Add r-squared\n",
    "    x = df[ev_column_name].values\n",
    "    y = df[rv_column_name].values\n",
    "    plt.text(0.92, 0.965, r'$r^2 = {0:.2}$'.format(stats.pearsonr(x, y)[0] ** 2), fontsize=20, alpha=0.25,\n",
    "             horizontalalignment='center', verticalalignment='center', transform=merge_axes_subplot.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from scipy import stats\n",
    "\n",
    "us_stats_df = load_object('us_stats_df')\n",
    "kwargs = dict(textcoords='offset points', ha='left', va='bottom',\n",
    "              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "              arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "ev_min_str = 'least black'\n",
    "ev_max_str = 'most black'\n",
    "rv_min_str = 'least murderous'\n",
    "rv_max_str = 'most murderous'\n",
    "ev_min_xytext = (-5, 150)\n",
    "ev_max_xytext = (-130, -100)\n",
    "rv_min_xytext = (20, -10)\n",
    "rv_max_xytext = (-100, -50)\n",
    "az_xytext = (-80, 60)\n",
    "columns_list = [ev_column_name, rv_column_name]\n",
    "show_linear_scatterplot(us_stats_df, columns_list, ev_min_str=ev_min_str, ev_max_str=ev_max_str, rv_min_str=rv_min_str, rv_max_str=rv_max_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = 'Total_Gun_Murder_Deaths_2010'\n",
    "cb1 = c.show_colorbar(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.pyplot import savefig\n",
    "\n",
    "savefig??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print([f'cb1.{fn}' for fn in dir(cb1) if 'fig' in fn.lower()])\n",
    "print([f'cb1.{fn}' for fn in dir(cb1) if 'ax' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(1, 6))\n",
    "print([f'plt.{fn}' for fn in dir(plt) if 'fig' in fn.lower()])\n",
    "print([f'plt.{fn}' for fn in dir(plt) if 'ax' in fn.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as fga\n",
    "\n",
    "canvas_obj = fga(figure=fig)\n",
    "print([f'fga.{fn}' for fn in dir(fga) if not fn.startswith('_')])\n",
    "print([f'canvas_obj.{fn}' for fn in dir(canvas_obj) if not fn.startswith('_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'Estimated_IQ' not in us_stats_df.columns:\n",
    "    if s.csv_exists('iq_by_us_state'):\n",
    "        iq_by_us_state_df = s.load_csv('iq_by_us_state')\n",
    "        iq_by_us_state_df.set_index('State', drop=True, inplace=True)\n",
    "        iq_by_us_state_df.columns = ['Estimated_IQ', 'Percent_Whites_in_Non_Public_Education', 'Gross_Product', 'Health', 'Violent_Crime',\n",
    "                                     'Government_Effectiveness']\n",
    "        us_stats_df = pd.merge(left=us_stats_df, right=iq_by_us_state_df, how='outer', left_index=True,\n",
    "                               right_index=True, suffixes=('_stats', '_iq'))\n",
    "        s.store_objects(us_stats_df=us_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if notebook_path is not None:\n",
    "    !start %windir%\\explorer.exe \"{os.path.abspath(os.path.dirname(notebook_path))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
